[TOC]

# Papers

## 如何实现ChatGPT的平替

## 如何往ChatGPT中注入知识

## 如何评估LLMs

# Blogs

# Videos

# TODO

Decoupling Knowledge From Memorization Retrieval-augmented Prompt Learning

[神奇LLM引擎上线：帮你把GPT-3直接调成ChatGPT](https://mp.weixin.qq.com/s/eBFjLfyLycdMIF6-ucgy1w)

[清华唐杰教授：从千亿模型到ChatGPT的⼀点思考](https://mp.weixin.qq.com/s/25cxLdYd37DHw6-UpZlayw)

# Else

`Language Models as Knowledge Bases?` EMNLP 2019.

*Fabio Petroni, Tim Rocktaschel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander H. Miller, Sebastian Riedel.* 2019.9 [[pdf](https://arxiv.org/abs/1909.01066)] [[project](https://arxiv.org/abs/1909.01066)]